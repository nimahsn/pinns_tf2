{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWzC4kfYa-Cd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "GiHtqYSvcH5B",
        "outputId": "56463764-c985-45ad-c05c-fac65e17a2c6"
      },
      "outputs": [],
      "source": [
        "class BurgersPinn(keras.Model):\n",
        "  def __init__(self, nu, network, n_inputs=2, n_outputs=1):\n",
        "    super().__init__()\n",
        "    self.network = network\n",
        "    self.nu = nu\n",
        "\n",
        "  def fit(self, inputs, epochs, optimizer, progress_interval=500):\n",
        "    \"\"\"\n",
        "    Train the model with the given inputs and optimizer.\n",
        "\n",
        "    Args:\n",
        "      inputs: A list of tensors, where the first tensor is the equation data,\n",
        "        the second tensor is the initial condition data, and the third tensor\n",
        "        is the boundary condition data.\n",
        "      epochs: The number of epochs to train for.\n",
        "      optimizer : The optimizer to use for training.\n",
        "      progress_interval: The number of epochs between each progress report.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "      with tf.GradientTape() as tape:\n",
        "        _, losses = self.call(inputs, training=True)\n",
        "        loss = tf.reduce_sum(losses)\n",
        "\n",
        "      grads = tape.gradient(loss, self.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "      if epoch % progress_interval == 0:\n",
        "        print(f\"Epoch: {epoch} Loss: {loss.numpy():.4f} Total Elapsed Time: {time.time() - start_time:.2f}\")\n",
        "\n",
        "  @tf.function\n",
        "  def input_gradient(self, x):\n",
        "    \"\"\"\n",
        "    Compute the first and second derivatives of the network output with respect to the input.\n",
        "    \n",
        "    Args:\n",
        "      x: input tensor of shape (n_inputs, 2)\n",
        "\n",
        "    returns:\n",
        "      u: network output of shape (n_inputs, 1)\n",
        "      u_t: first derivative of u with respect to t\n",
        "      u_x: first derivative of u with respect to x\n",
        "      u_xx: second derivative of u with respect to x\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as g2tape: # grad tape for getting second order derivatives\n",
        "      g2tape.watch(x) # gradients w.r.t. inputs\n",
        "      with tf.GradientTape() as gtape: # grad tape for first order drivatives\n",
        "        gtape.watch(x)\n",
        "        u = self.network(x)\n",
        "        \n",
        "      first_order = gtape.batch_jacobian(u, x)\n",
        "      u_t = first_order[..., 0]\n",
        "      u_x = first_order[..., 1]\n",
        "      \n",
        "    u_xx = g2tape.batch_jacobian(u_x, x)[..., 1]\n",
        "    return u, u_t, u_x, u_xx\n",
        "  \n",
        "  def call(self, inputs, training=True):\n",
        "    \"\"\"\n",
        "    Performs forward pass of the model, computing the loss and returning it. If training is True, the\n",
        "    loss is also computed for the initial and boundary conditions.\n",
        "\n",
        "    Args:\n",
        "      inputs: If training is True, a list of tensors, where the first tensor is the equation data,\n",
        "        the second tensor is the initial condition data, and the third tensor\n",
        "        is the boundary condition data. If training is False, a single tensor of shape (n_inputs, 2).\n",
        "      training: Whether or not to compute the loss for the initial and boundary conditions. Defaults to True.\n",
        "    returns:\n",
        "      u: network output of shape (n_inputs, 1)\n",
        "    \"\"\"\n",
        "    if training:\n",
        "      tx_equation = inputs[0]\n",
        "    else:\n",
        "      tx_equation = inputs\n",
        "    u, u_t, u_x, u_xx = self.input_gradient(tx_equation)\n",
        "    burgers_eq = u_t + u*u_x - self.nu*u_xx\n",
        "    \n",
        "    losses = tf.stack([tf.reduce_mean(tf.square(burgers_eq))])\n",
        "\n",
        "    if training:\n",
        "      tx_init = inputs[1]\n",
        "      tx_bound = inputs[2]\n",
        "      n_i = tx_init.shape[0]\n",
        "      u_ib = self.network(tf.concat([tx_init, tx_bound], axis = 0))\n",
        "\n",
        "\n",
        "      init_loss = tf.reduce_mean(tf.square(u_ib[:n_i] - tf.sin(np.pi*tx_init[..., 1])))\n",
        "      boundary_loss = tf.reduce_mean(tf.square(u_ib[n_i:]))\n",
        "      losses = tf.concat([losses, [init_loss, boundary_loss]], axis=0)\n",
        "\n",
        "      return burgers_eq, losses\n",
        "\n",
        "    return burgers_eq, losses\n",
        "  \n",
        "  @staticmethod\n",
        "  def build_network(layers, n_inputs=2, n_outputs=1, activation=keras.activations.tanh, initialization=keras.initializers.glorot_normal):\n",
        "    \"\"\"\n",
        "    Builds a fully connected neural network with the specified number of layers and nodes per layer.\n",
        "\n",
        "    Args:\n",
        "        layers (list): List of integers specifying the number of nodes in each layer.\n",
        "        n_inputs (int): Number of inputs to the network.\n",
        "        n_outputs (int): Number of outputs from the network.\n",
        "        activation (function): Activation function to use in each layer.\n",
        "        initialization (function): Initialization function to use in each layer.\n",
        "    returns:\n",
        "        keras.Model: A keras model representing the neural network.\n",
        "    \"\"\"\n",
        "    inputs = keras.layers.Input((n_inputs))\n",
        "    x = inputs\n",
        "    for i in layers:\n",
        "      x = keras.layers.Dense(i, activation = activation, kernel_initializer=initialization)(x)\n",
        "    \n",
        "    outputs = keras.layers.Dense(n_outputs, kernel_initializer=initialization)(x)\n",
        "    return keras.Model(inputs=[inputs], outputs = [outputs])\n",
        "\n",
        "  @staticmethod\n",
        "  def simulate_burgers(n_samples, training = True, dtype=tf.float32, boundary_samples = None, random_seed = 42):\n",
        "    \"\"\"\n",
        "    Simulate the burgers equation\n",
        "\n",
        "    Args:\n",
        "        n_samples (int): number of samples to generate\n",
        "        training (bool, optional): If true, generates initial and boundary samples as well. Defaults to True.\n",
        "        dtype (tf.dtype, optional): Data type of the samples. Defaults to tf.float32.\n",
        "        boundary_samples (int, optional): Number of boundary samples to generate. No effext if training = False. Defaults to None.\n",
        "        random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
        "    returns:\n",
        "        tf.Tensor: Samples of the burgers equation. If training = True, returns a tuple of tensors (equation_samples, initial_samples, boundary_samples).\n",
        "    \"\"\"\n",
        "    r = np.random.RandomState(random_seed)\n",
        "    tx_samples = r.uniform(0, 1, (n_samples, 2))\n",
        "    tx_samples[:, 1] = tx_samples[:, 1]*2 - 1\n",
        "\n",
        "    if training:\n",
        "      tx_init = np.zeros((boundary_samples, 1))\n",
        "      tx_init = np.append(tx_init, r.uniform(-1, 1, (boundary_samples, 1)), axis=1)\n",
        "\n",
        "      tx_boundary = r.uniform(0, 1, (boundary_samples, 1))\n",
        "      ones = np.ones((boundary_samples//2, 1))\n",
        "      ones = np.append(ones, -np.ones((boundary_samples - boundary_samples//2, 1)), axis=0)\n",
        "      tx_boundary = np.append(tx_boundary, ones, axis=1)\n",
        "      r.shuffle(tx_boundary)\n",
        "      return tf.convert_to_tensor(tx_samples, dtype=dtype), tf.convert_to_tensor(tx_init, dtype=dtype), tf.convert_to_tensor(tx_boundary, dtype=dtype)\n",
        "    \n",
        "    return tx_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTt_kvzss1RP"
      },
      "outputs": [],
      "source": [
        "network = BurgersPinn.build_network([16, 32])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLxhOPlPuOAU"
      },
      "outputs": [],
      "source": [
        "pinn_model = BurgersPinn(0.01*np.pi, network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0bDLHc8u05V"
      },
      "outputs": [],
      "source": [
        "tx_samples, tx_init, tx_boundary = BurgersPinn.simulate_burgers(1000, training=True, boundary_samples=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pinn_model.network.build((None, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pinn_model.network.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fim422wu7GF"
      },
      "outputs": [],
      "source": [
        "pinn_model.fit(tf.stack([tx_samples, tx_init, tx_boundary], axis=0), epochs=5000, optimizer=keras.optimizers.Adam(lr=0.01), progress_interval=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6N3iwR_vDX9"
      },
      "outputs": [],
      "source": [
        "num_test_samples = 1000\n",
        "t_flat = np.linspace(0, 1, num_test_samples)\n",
        "x_flat = np.linspace(-1, 1, num_test_samples)\n",
        "t, x = np.meshgrid(t_flat, x_flat)\n",
        "tx = np.stack([t.flatten(), x.flatten()], axis=-1)\n",
        "u = pinn_model.network.predict(tx, batch_size=num_test_samples)\n",
        "u = u.reshape(t.shape)\n",
        "\n",
        "# plot u(t,x) distribution as a color-map\n",
        "fig = plt.figure(figsize=(7,4))\n",
        "gs = GridSpec(2, 5)\n",
        "plt.subplot(gs[0, :])\n",
        "plt.pcolormesh(t, x, u)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "cbar = plt.colorbar(pad=0.05, aspect=10)\n",
        "cbar.set_label('u(t,x)')\n",
        "cbar.mappable.set_clim(-1, 1)\n",
        "# plot u(t=const, x) cross-sections\n",
        "t_cross_sections = [0,0.25, 0.5,0.75,1]\n",
        "for i, t_cs in enumerate(t_cross_sections):\n",
        "  plt.subplot(gs[1, i])\n",
        "  tx = np.stack([np.full(t_flat.shape, t_cs), x_flat], axis=-1)\n",
        "  u = pinn_model.network.predict(tx, batch_size=num_test_samples)\n",
        "  plt.plot(x_flat, u)\n",
        "  plt.title('t={}'.format(t_cs))\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('u(t,x)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('tf2-pinn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e186c38e7d8b9112f5aec0d01a09336163341258afaa29e2c2eecdf076e8d0c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
